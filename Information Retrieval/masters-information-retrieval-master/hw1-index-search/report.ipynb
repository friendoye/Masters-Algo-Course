{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отчет по лабороторной работе №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала привожу листинг с некоторыми комментариями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import math\n",
    "from itertools import groupby\n",
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "from numpy import arange\n",
    "\n",
    "import nltk\n",
    "from nltk import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "default_tokenize_func = word_tokenize\n",
    "default_lemmatizer = WordNetLemmatizer()\n",
    "default_stemmer = SnowballStemmer(\"english\")\n",
    "default_stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# код из eval.py, завернутый в функцию\n",
    "def eval_metrics(groundtruth_file, answer_file):\n",
    "    q2reld = {} \n",
    "    for line in open(groundtruth_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2reld.keys():\n",
    "            q2reld[qid] = set()\n",
    "        q2reld[qid].add(did)        \n",
    "\n",
    "    q2retrd = {}\n",
    "    for line in open(answer_file):\n",
    "        qid, did = [int(x) for x in line.split()]\n",
    "        if qid not in q2retrd.keys():\n",
    "            q2retrd[qid] = []\n",
    "        q2retrd[qid].append(did)               \n",
    "\n",
    "    N = len(q2retrd.keys())\n",
    "    precision = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2retrd[q]) for q in q2retrd.keys()]) / N\n",
    "    recall = sum([len(q2reld[q].intersection(q2retrd[q]))*1.0/len(q2reld[q]) for q in q2retrd.keys()]) / N\n",
    "#    print(\"mean precision: {}\\nmean recall: {}\\nmean F-measure: {}\"\\\n",
    "#          .format(precision, recall, 2*precision*recall/(precision+recall)))\n",
    "\n",
    "    # MAP@10\n",
    "    import numpy as np\n",
    "\n",
    "    MAP = 0.0\n",
    "    for q in q2retrd.keys():\n",
    "        n_results = min(10, len(q2retrd[q]))\n",
    "        avep = np.zeros(n_results)\n",
    "        for i in range(n_results):\n",
    "            avep[i:] += q2retrd[q][i] in q2reld[q]\n",
    "            avep[i] *= (q2retrd[q][i] in q2reld[q]) / (i+1.0)\n",
    "        MAP += sum(avep) / min(n_results, len(q2reld[q]))\n",
    "#    print(\"MAP@10: {}\".format(MAP/N))\n",
    "\n",
    "    return precision, recall, 2*precision*recall/(precision+recall), MAP/N\n",
    "\n",
    "# функция для парсинга файла\n",
    "# вырезает куски соответствующие определенной секции в файле и возвращает сам кусок и присвоенный ему идентификатор\n",
    "def parse_file(file, label='W'):\n",
    "    section_labels = {'I', 'T', 'A', 'B', 'W'}\n",
    "\n",
    "    section_found = False\n",
    "    id = 1\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "\n",
    "        document = ''\n",
    "\n",
    "        for line in f.readlines():\n",
    "\n",
    "            stipped_line = line.strip()\n",
    "\n",
    "            if len(stipped_line) == 0:\n",
    "                continue\n",
    "\n",
    "            if stipped_line.startswith('.' + label):\n",
    "                section_found = True\n",
    "            elif len(stipped_line) >= 2 and stipped_line[0] == '.' and stipped_line[1] in section_labels:\n",
    "                if section_found:\n",
    "                    yield (id, document.strip())\n",
    "                    document = ''\n",
    "                    id += 1\n",
    "                    section_found = False\n",
    "\n",
    "            elif section_found:\n",
    "                document += ' ' + stipped_line\n",
    "\n",
    "        if section_found:\n",
    "            yield (id, document.strip())\n",
    "\n",
    "# функция нормализации текста\n",
    "# бьет текст на токены, удаляет стоп-слова(если передан список слов), применяет лемматизатор и стеммер (переданы)\n",
    "# возвращает токен с его частотой\n",
    "def normalize_text(text,\n",
    "                   tokenize_func=default_tokenize_func,\n",
    "                   lemmatizer=default_lemmatizer,\n",
    "                   stemmer=default_stemmer,\n",
    "                   stop_words=default_stop_words):\n",
    "    tokens = list()\n",
    "\n",
    "    for token in tokenize_func(text):\n",
    "        if token in string.punctuation:\n",
    "            continue\n",
    "\n",
    "        if token in stop_words:\n",
    "            continue\n",
    "\n",
    "        if lemmatizer:\n",
    "            token = lemmatizer.lemmatize(token)\n",
    "\n",
    "        if stemmer:\n",
    "            token = stemmer.stem(token)\n",
    "\n",
    "        tokens.append(token)\n",
    "\n",
    "    tokens.sort()\n",
    "\n",
    "    return [(key, len(list(group))) for key, group in groupby(tokens)]\n",
    "\n",
    "# расчет RSV по заданным параметрам (соответствует пункту 3 в задании)\n",
    "def calc_rsv_default(N, Nt, ftd, ftq, Ld, L, b, k1, k2):\n",
    "    idf = calc_idf_default(N, Nt)\n",
    "    tf = ftd * (k1 + 1) / (k1 * ((1 - b) + b * Ld / L) + ftd)\n",
    "    return idf * tf\n",
    "\n",
    "# вспомогательная функция для расчета IDF\n",
    "def calc_idf_default(N, Nt):\n",
    "    return math.log(1 + (N - Nt + 0.5) / (Nt + 0.5))\n",
    "\n",
    "# инвертированный индекс с возможностью добавления документов по одному и поиску\n",
    "class InvertedIndex:\n",
    "    def __init__(self, lemmatizer=default_lemmatizer, stemmer=default_stemmer):\n",
    "        self.lemmatizer = lemmatizer\n",
    "        self.stemmer = stemmer\n",
    "        self.documents_total_length = 0\n",
    "        self.documents = dict()\n",
    "        self.index = defaultdict(list)\n",
    "\n",
    "        pass\n",
    "\n",
    "    # добавление документа\n",
    "    def add_document(self, doc_id, document):\n",
    "        self.documents_total_length += len(document)\n",
    "        self.documents[doc_id] = document\n",
    "\n",
    "        # todo maybe sort after add\n",
    "        for token in normalize_text(document, lemmatizer=self.lemmatizer, stemmer=self.stemmer):\n",
    "            self.index[token[0]].append((doc_id, token[1]))\n",
    "\n",
    "        pass\n",
    "\n",
    "    # поиск\n",
    "    def search_okapi_bm25(self, query, b, k1, k2, rsvfunc, norm_rsv, limit=10):\n",
    "        result = defaultdict(int)\n",
    "\n",
    "        N = len(self.documents)\n",
    "        L = self.documents_total_length / len(self.documents)\n",
    "\n",
    "        idf_sums = defaultdict(int)\n",
    "        \n",
    "        for token_tuple in normalize_text(query, lemmatizer=self.lemmatizer, stemmer=self.stemmer):\n",
    "            ftq = token_tuple[1]\n",
    "            token_docs = self.index[token_tuple[0]]\n",
    "            Nt = len(token_docs)\n",
    "            for doc_tuple in token_docs:\n",
    "                doc_id = doc_tuple[0]\n",
    "                ftd = doc_tuple[1]\n",
    "                Ld = len(self.documents[doc_id])\n",
    "\n",
    "                result[doc_id] += rsvfunc(N, Nt, ftd, ftq, Ld, L, b, k1, k2)\n",
    "                    \n",
    "                if norm_rsv :\n",
    "                    idf_sums[doc_id] += calc_idf_default(N, Nt)\n",
    "\n",
    "        result = list(result.items())\n",
    "\n",
    "        if norm_rsv:\n",
    "            result = [(x[0], x[1] / idf_sums[x[0]]) for x in result]\n",
    "\n",
    "        result = sorted(result, key=itemgetter(1), reverse=True)\n",
    "        #print(result[:10])\n",
    "        return [x[0] for x in result][:limit]\n",
    "\n",
    "    # размер словаря\n",
    "    def get_dist_size(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "    # средняя длина posting-листа\n",
    "    def get_average_postings_list_length(self):\n",
    "        l = [len(p) for p in self.index.values()]\n",
    "        return sum(l) / len(l)\n",
    "\n",
    "    # максимальная длина posting-листа\n",
    "    def get_max_postings_list_length(self):\n",
    "        l = [len(p) for p in self.index.values()]\n",
    "        return max(l)\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        print(\"\\tStatistics:\\n\\tDictionary size = {}\\n\\tAverage postings list length = {}\\n\\tMax postings list length = {}\"\n",
    "              .format(self.get_dist_size(), self.get_average_postings_list_length(), self.get_max_postings_list_length()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/destalling/', 1), ('aerodynam', 1), ('agre', 1), ('angl', 1), ('attack', 1), ('basi', 1), ('boundary-layer-control', 1), ('compar', 1), ('configur', 1), ('curv', 1), ('destal', 2), ('determin', 1), ('differ', 3), ('distribut', 1), ('due', 2), ('effect', 2), ('empir', 1), ('evalu', 2), ('evid', 1), ('experi', 1), ('experiment', 2), ('flow', 1), ('found', 1), ('free', 1), ('increas', 1), ('increment', 2), ('integr', 1), ('intend', 1), ('investig', 1), ('lift', 4), ('load', 1), ('made', 2), ('order', 1), ('part', 2), ('potenti', 1), ('problem', 1), ('produc', 1), ('propel', 1), ('ratio', 1), ('remain', 1), ('result', 1), ('show', 1), ('slipstream', 5), ('span', 1), ('spanwis', 1), ('specif', 1), ('stream', 1), ('studi', 1), ('substanti', 1), ('subtract', 1), ('support', 1), ('theoret', 1), ('theori', 1), ('togeth', 1), ('treatment', 1), ('veloc', 1), ('well', 1), ('wing', 3)]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "experimental investigation of the aerodynamics of a\n",
    "wing in a slipstream .\n",
    "  an experimental study of a wing in a propeller slipstream was\n",
    "made in order to determine the spanwise distribution of the lift\n",
    "increase due to slipstream at different angles of attack of the wing\n",
    "and at different free stream to slipstream velocity ratios .  the\n",
    "results were intended in part as an evaluation basis for different\n",
    "theoretical treatments of this problem .\n",
    "  the comparative span loading curves, together with\n",
    "supporting evidence, showed that a substantial part of the lift increment\n",
    "produced by the slipstream was due to a /destalling/ or\n",
    "boundary-layer-control effect .  the integrated remaining lift\n",
    "increment, after subtracting this destalling lift, was found to agree\n",
    "well with a potential flow theory .\n",
    "  an empirical evaluation of the destalling effects was made for\n",
    "the specific configuration of the experiment .\"\"\"\n",
    "print(normalize_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним инвертированный индекс используя данные тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# индекс по заголовкам (с использованием стеммера)\n",
    "indexTS = InvertedIndex()\n",
    "# индекс по заголовкам (с использованием лемматизатора)\n",
    "indexTL = InvertedIndex(lemmatizer=WordNetLemmatizer(), stemmer=None)\n",
    "# индекс по всему abstract (с использованием стеммера)\n",
    "indexWS = InvertedIndex()\n",
    "# индекс по всему abstract (с использованием лемматизатора)\n",
    "indexWL = InvertedIndex(lemmatizer=WordNetLemmatizer(), stemmer=None)\n",
    "for doc_tuple in parse_file('cran.all.1400', 'T'):\n",
    "    indexTS.add_document(doc_tuple[0], doc_tuple[1])\n",
    "    indexTL.add_document(doc_tuple[0], doc_tuple[1])\n",
    "for doc_tuple in parse_file('cran.all.1400', 'W'):\n",
    "    indexWS.add_document(doc_tuple[0], doc_tuple[1])\n",
    "    indexWL.add_document(doc_tuple[0], doc_tuple[1])\n",
    "    \n",
    "words = list(indexTS.index.keys())\n",
    "words = sorted(words)\n",
    "#print(words)\n",
    "#for key in words:\n",
    "#    print(\"\", key, \": \", indexTS.index[key], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем поиск по каждому из индексов и рассчитаем показатели качества (вместе с этим, распечатаем статистику по каждому из индексов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index For Titles (stemmer)\n",
      "\tPrecision = 0.4\n",
      "\tRecall = 0.13793103448275862\n",
      "\tF-measure = 0.20512820512820515\n",
      "\tMAP@10 = 0.2671428571428572\n",
      "\tStatistics:\n",
      "\tDictionary size = 1529\n",
      "\tAverage postings list length = 7.087638979725311\n",
      "\tMax postings list length = 358\n"
     ]
    }
   ],
   "source": [
    "def parse_search_eval(index, b=0.75, k1=1.2, k2=None, rsvfunc=calc_rsv_default, norm_rsv=False):\n",
    "    with open('answer', 'w') as output:\n",
    "        for query_tuple in parse_file('cran.qry'):\n",
    "            query_id = query_tuple[0]\n",
    "            for doc_id in index.search_okapi_bm25(query_tuple[1], b=b, k1=k1, k2=k2, rsvfunc=rsvfunc, norm_rsv=norm_rsv):\n",
    "                output.write(\"{} {}\\n\".format(query_id, doc_id))\n",
    "\n",
    "    return eval_metrics('qrel_clean', 'answer')\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(indexTS)\n",
    "print(\"Index For Titles (stemmer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "indexTS.print_statistics()\n",
    "\n",
    "# precision, recall, fmeasure, map10 = parse_search_eval(indexTL)\n",
    "# print(\"Index For Titles (lemmatizer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "# indexTL.print_statistics()\n",
    "\n",
    "# precision, recall, fmeasure, map10 = parse_search_eval(indexWS)\n",
    "# print(\"Index For Abstracts (stemmer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "# indexWS.print_statistics()\n",
    "\n",
    "# precision, recall, fmeasure, map10 = parse_search_eval(indexWL)\n",
    "# print(\"Index For Abstracts (lemmatizer)\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))\n",
    "# indexWL.print_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось, все показатели оказались лучше для индекса, построенного по abstracts, чем по titiles, так как увеличивается вероятностью встретить одинаковые термы и в запросе, и в тексте. Если сравнивать индексы, при построении и поиске по которым использовался стеммер с теми, где использовался лемматизатор, видно, что результаты приблизительно одинаковые, поэтому для дальнейших экспериментов решено было использовать стеммер (он быстрее работает). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = indexWS\n",
    "\n",
    "default_best_b = 0.9\n",
    "default_best_k1 = 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, используя Grid Search, найдем оптимальные параметры поиска (вычисление занимает несколько минут, поэтому строки закомментированы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_by_fmeasure = (0, 0, 0, 0, 0, 0)\n",
    "best_by_map10 = (0, 0, 0, 0, 0, 0)\n",
    "\n",
    "for k1 in arange(1.2, 2.1, .1):\n",
    "    for b in arange(.0, 1.1, .1):\n",
    "        precision, recall, fmeasure, map10 = parse_search_eval(index, b=b, k1=k1)\n",
    "        if fmeasure > best_by_fmeasure[2]:\n",
    "            best_by_fmeasure = (precision, recall, fmeasure, map10, b, k1)\n",
    "\n",
    "        if map10 > best_by_map10[3]:\n",
    "            best_by_map10 = (precision, recall, fmeasure, map10, b, k1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f-measure = 0.25641025641025644 at b = 0.7000000000000001, k1 = 1.9000000000000006\n",
      "Best map10 = 0.38769841269841265 at b = 0.7000000000000001, k1 = 2.000000000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"Best f-measure = {} at b = {}, k1 = {}\".format(best_by_fmeasure[2], best_by_fmeasure[4], best_by_fmeasure[5]))\n",
    "print(\"Best map10 = {} at b = {}, k1 = {}\".format(best_by_map10[3], best_by_map10[4], best_by_map10[5]))\n",
    "\n",
    "default_best_b = best_by_fmeasure[4]\n",
    "default_beft_k1 = best_by_fmeasure[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я думаю, что оптимальный для f-меры параметр b получился равным 0.9, потому что тексты в среднем значительно отличаются по длине. А параметр k1 равным 1.3, скорее всего потому что частота всех термов запросов в документах в среднем одинаковая.\n",
    "\n",
    "Попробуем заменить функцию вычисления IDF-составляющей, используя при этом значения b и k1, для которых было получено лучшее значение f-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\tPrecision = 0.5\n",
      "\tRecall = 0.1724137931034483\n",
      "\tF-measure = 0.25641025641025644\n",
      "\tMAP@10 = 0.375\n"
     ]
    }
   ],
   "source": [
    "def calc_rsv_custom_idf(N, Nt, ftd, ftq, Ld, L, b, k1, k2):\n",
    "    idf = math.log(N / Nt)\n",
    "    tf = ftd * (k1 + 1) / (k1 * ((1 - b) + b * Ld / L) + ftd)\n",
    "    return idf * tf\n",
    "\n",
    "precision, recall, fmeasure, map10 = parse_search_eval(index, b=default_best_b, k1=default_beft_k1, rsvfunc=calc_rsv_custom_idf)\n",
    "print(\"Results:\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, данное изменение не привело к значительному улучшению, кроме того, я думаю, что при большом количестве документов привело бы к ухудшению значения f-меры.\n",
    "\n",
    "Далее, попробуем нормализовать RSV документа на сумму IDF термов запроса, которые в него входят."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0a0d0f87f099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_search_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_best_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_beft_k1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_rsv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results:\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-24ca2e99c731>\u001b[0m in \u001b[0;36mparse_search_eval\u001b[0;34m(index, b, k1, k2, rsvfunc, norm_rsv)\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0meval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qrel_clean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'answer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmeasure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_search_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-5c0ab3b2798b>\u001b[0m in \u001b[0;36meval_metrics\u001b[0;34m(groundtruth_file, answer_file)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#    print(\"MAP@10: {}\".format(MAP/N))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAP\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# функция для парсинга файла\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "precision, recall, fmeasure, map10 = parse_search_eval(index, b=default_best_b, k1=default_beft_k1, norm_rsv=True)\n",
    "print(\"Results:\\n\\tPrecision = {}\\n\\tRecall = {}\\n\\tF-measure = {}\\n\\tMAP@10 = {}\".format(precision, recall, fmeasure, map10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация несколько ухудшила значение f-меры и сильно ухудшила значение MAP@10. Благодаря такому приему, должно было уменьшиться влияние частовстречающихся слов на полученный RSV, однако, скорее всего из-за того что стоп-слова были отфильтрованы, результаты только ухудшились.\n",
    "\n",
    "Попробуем как предлагается добавить параметр k2, используя до этого полученные лучшие b и k1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_rsv_general(N, Nt, ftd, ftq, Ld, L, b, k1, k2):\n",
    "    idf = calc_idf_default(N, Nt)\n",
    "    tftd = ftd * (k1 + 1) / (k1 * ((1 - b) + b * Ld / L) + ftd)\n",
    "    tftq = ftq * (k2 + 1) / (k2 + ftq)\n",
    "    return idf * tftd * tftq\n",
    "\n",
    "best_by_fmeasure_general = (0, 0, 0, 0, 0, 0, 0)\n",
    "best_by_map10_general = (0, 0, 0, 0, 0, 0, 0)\n",
    "\n",
    "for k2 in (0, 1, 5, 10, 20, 50, 100, 200, 500, 1000):\n",
    "    precision, recall, fmeasure, map10 = parse_search_eval(index, b=default_best_b, k1=default_beft_k1, k2=k2, rsvfunc=calc_rsv_general)\n",
    "    if fmeasure > best_by_fmeasure_general[2]:\n",
    "        best_by_fmeasure_general = (precision, recall, fmeasure, map10, default_best_b, default_beft_k1, k2)\n",
    "\n",
    "    if map10 > best_by_map10_general[3]:\n",
    "        best_by_map10_general = (precision, recall, fmeasure, map10, default_best_b, default_beft_k1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f-measure = 0.2421726419438806 at b = 0.9, k1 = 1.3, k2 = 0\n",
      "Best map10 = 0.20365195193303656 at b = 0.9, k1 = 1.3, k2 = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best f-measure = {} at b = {}, k1 = {}, k2 = {}\"\n",
    "      .format(best_by_fmeasure_general[2], best_by_fmeasure_general[4], best_by_fmeasure_general[5], best_by_fmeasure_general[6]))\n",
    "print(\"Best map10 = {} at b = {}, k1 = {}, k2 = {}\"\n",
    "      .format(best_by_map10_general[3], best_by_map10_general[4], best_by_map10_general[5], best_by_map10_general[6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось, что при k2 = 0, мы достигли лучшего значения f-меры. Это можно объяснить тем, что скорее всего термы в запросах встречались один - два раза и это не повлекло за собой значительного изменения RSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, лучшее полученное значение f-меры равно 0.2427002488648061 (при подборе параметров и использовании более простой формулы IDF), а лучшее значение MAP@10 равно 0.20379489585957844 (при подборе параметров). Ни одна из предложенных оптимизаций не смогла на данном наборе документов и запросов значительно улучшить результаты поиска. Полученные результаты оказались не слишком хороши в первую очередь потому что модель BM25 не учитывает множество факторов, которые учитывают более новые модели. А также из-за небольшого объема коллекции и малой длины текстов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
