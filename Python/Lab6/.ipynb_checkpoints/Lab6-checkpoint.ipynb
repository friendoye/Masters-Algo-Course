{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!** Данную лабораторную нужно выполнять на **Python 3.6+**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Работа с метаклассами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.1 (0.6 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте метакласс **BoundedMeta**, который контролирует количество созданных объектов классов, которые имеют данный метакласс. Допустимое количество объектов задайте параметром (по умолчанию 1).\n",
    "\n",
    "В случае превышения бросайте исключение **TypeError**. Eсли значение параметра - **None**, то ограничений нету.\n",
    "\n",
    "Другими словами, у класса **C** с метаклассом **BoundedMeta** должно быть создано не более 2 экземпляров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything works fine!\n"
     ]
    }
   ],
   "source": [
    "class BoundedMeta(type):\n",
    "    _counter = 0\n",
    "    \n",
    "    def __new__(cls, name, bases, namespace, **kargs):\n",
    "        return super().__new__(cls, name, bases, namespace)\n",
    "\n",
    "    def __init__(cls, name, bases, namespace, max_instance_count = 1, **kargs):\n",
    "        cls._max_instance_count = max_instance_count\n",
    "        super().__init__(name, bases, namespace)\n",
    "\n",
    "    def __call__(cls):\n",
    "        if (cls._max_instance_count is not None) and (cls._counter >= cls._max_instance_count):\n",
    "            raise TypeError()\n",
    "        cls._counter += 1\n",
    "        return super().__call__()\n",
    "\n",
    "class C(metaclass=BoundedMeta, max_instance_count=2):\n",
    "    pass\n",
    "\n",
    "c1 = C()\n",
    "c2 = C()\n",
    "\n",
    "try:\n",
    "    c3 = C()\n",
    "except TypeError:\n",
    "    print('everything works fine!')\n",
    "else:\n",
    "    print('something goes wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.2 (0.6 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс **BoundedBase**, в котором определен абстрактный classmethod get_max_instance_count, возвращающий максимальное количество экзмепляров, которые можно создать.\n",
    "\n",
    "Не допускайте ***создания*** объекта, если данное значение превышено - бросайте исключение **TypeError**. Значение, равное **None** - без ограничений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything works fine!\n"
     ]
    }
   ],
   "source": [
    "from abc import *\n",
    "\n",
    "class BoundedBase(ABC):\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def get_max_instance_count(cls):\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def _check_counter_var(cls):\n",
    "        try:\n",
    "            test = cls._counter\n",
    "        except AttributeError:\n",
    "            cls._counter = 0\n",
    "    \n",
    "    def __new__(cls, **kargs):\n",
    "        cls._check_counter_var()\n",
    "        max_cls_count = cls.get_max_instance_count()\n",
    "        if (max_cls_count is not None) and (cls._counter >= max_cls_count):\n",
    "            raise TypeError()\n",
    "        cls._counter += 1\n",
    "        return super().__new__(cls)\n",
    "    \n",
    "    \n",
    "class D(BoundedBase):\n",
    "    @classmethod\n",
    "    def get_max_instance_count(cls):\n",
    "        return 1\n",
    "    \n",
    "d1 = D()\n",
    "\n",
    "try:\n",
    "    d2 = D()\n",
    "except TypeError:\n",
    "    print('everything works fine!')\n",
    "else:\n",
    "    print('something goes wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Работа с NumPy и SciPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В области машинного обучения одним из самых популярных методов бинарной классификации (предсказываем один из двух классов, $+1$ или $-1$ для каждого объекта) является логистическая регрессия. Она выводится из метода максимального правдоподобия, который приводит к следующей задаче оптимизации:\n",
    "\n",
    "$$ L(w, X, y) = \\frac1{N}\\sum_{i = 0}^{N} log (1 + exp(-y_ix_i^Tw)) + \\frac{C}{2} ||w||^2 \\longrightarrow \\min_w$$\n",
    "$$X \\in R^{N \\times M}, x \\in R^{M}, w \\in R^{M}, y \\in \\{-1, 1\\}^N$$\n",
    "\n",
    "Здесь $X$ - матрица объекты-признаки для обучающей выборки (по строкам объекты, по столбцам признаки), а $y$ - вектор ответов. Коэффициент $C$, вообще говоря, нужно подбирать отдельно, поскольку разные его значения приводят к разным решениям задачи оптимизации. Но в этой задаче положим $\\mathbf{C = 10^{-3}}$\n",
    "\n",
    "Когда мы решили задачу оптимизации (нашли $w$), мы принимаем решение о том, к какому классу относится объект по правилу $y(x) = sign(x^Tw)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестирования правильности вычисления сгенерируем аргументы небольшого размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_size, features_count = 25, 10\n",
    "w = np.random.random(features_count)\n",
    "X, y = np.random.random((sample_size, features_count)), 2 * (np.random.randint(0, 2, sample_size) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.1 (0.2 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XY = np.hstack((X, y[:, np.newaxis]))\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного поработаем с ndarray. Получите из массива XY обратно X и y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47943316  0.96748275  0.21525601  0.56288243  0.34452281  0.7597561\n",
      "   0.12279985  0.04224322  0.55474249  0.38358227]\n",
      " [ 0.8644011   0.18155884  0.36992103  0.6948626   0.14891005  0.77912819\n",
      "   0.91893693  0.40671763  0.71905181  0.78601628]\n",
      " [ 0.5268153   0.42845457  0.46720848  0.66025677  0.80310226  0.78692024\n",
      "   0.40496498  0.38841005  0.2452937   0.31195825]\n",
      " [ 0.80597293  0.22258376  0.60449312  0.99112405  0.49266365  0.46381844\n",
      "   0.30652502  0.63968973  0.09166051  0.18971217]\n",
      " [ 0.08551793  0.82155052  0.58232437  0.69938756  0.18574334  0.98302113\n",
      "   0.59810873  0.69226518  0.37601594  0.22270991]\n",
      " [ 0.70520798  0.11594947  0.82622207  0.86681431  0.85900211  0.432353\n",
      "   0.72698221  0.70853753  0.62938548  0.31107697]\n",
      " [ 0.62550631  0.99541188  0.96827579  0.52968688  0.5370013   0.22811133\n",
      "   0.80107689  0.29121422  0.80715202  0.06923274]\n",
      " [ 0.07386807  0.18628828  0.88312855  0.39229589  0.90331145  0.8492079\n",
      "   0.44866773  0.90795022  0.73543276  0.4671008 ]\n",
      " [ 0.57807089  0.76566675  0.10644829  0.94696214  0.00120341  0.41093115\n",
      "   0.04233326  0.35647212  0.79159035  0.45379839]\n",
      " [ 0.85387327  0.98632415  0.56702864  0.38975009  0.4471529   0.5323866\n",
      "   0.57802124  0.77622977  0.89635356  0.49498517]\n",
      " [ 0.66180777  0.40602582  0.96785791  0.42907633  0.67532208  0.90292676\n",
      "   0.38355261  0.09835157  0.97752344  0.19185024]\n",
      " [ 0.15254628  0.71063701  0.4999327   0.93556535  0.3267875   0.83208677\n",
      "   0.16184053  0.5833935   0.41978107  0.18424715]\n",
      " [ 0.45655823  0.59370444  0.71809571  0.1885701   0.23056897  0.39487107\n",
      "   0.78054806  0.34356722  0.78913727  0.83131136]\n",
      " [ 0.06160249  0.86481325  0.59451728  0.01639225  0.21598775  0.43822656\n",
      "   0.75257939  0.34660523  0.93888072  0.49035221]\n",
      " [ 0.39252265  0.36051961  0.38068356  0.85571914  0.17176159  0.35989474\n",
      "   0.85464532  0.85011053  0.35776537  0.94612463]\n",
      " [ 0.55021438  0.42046699  0.2791844   0.50786667  0.49693874  0.76755223\n",
      "   0.95172688  0.58342475  0.52737107  0.02273525]\n",
      " [ 0.82288538  0.22086108  0.96287721  0.86298974  0.11058915  0.35198612\n",
      "   0.65332956  0.42259364  0.1974242   0.52112498]\n",
      " [ 0.78940168  0.27952084  0.51224172  0.73528109  0.51577483  0.32972626\n",
      "   0.78811023  0.05231083  0.33877323  0.844679  ]\n",
      " [ 0.25318169  0.55386103  0.71221257  0.60019481  0.43581807  0.64096438\n",
      "   0.66943638  0.80881334  0.26368999  0.58179637]\n",
      " [ 0.9438767   0.08845675  0.43010107  0.91699526  0.44874     0.70248572\n",
      "   0.5536997   0.00200746  0.77265783  0.789389  ]\n",
      " [ 0.35223639  0.42697752  0.68561197  0.12719727  0.89379481  0.47937941\n",
      "   0.30942218  0.97796201  0.26682026  0.71494031]\n",
      " [ 0.04557883  0.59309894  0.29522126  0.49960964  0.9903147   0.86653542\n",
      "   0.47328464  0.38135193  0.54394769  0.3876331 ]\n",
      " [ 0.88244365  0.25535284  0.34976555  0.43907657  0.63815839  0.54828725\n",
      "   0.79543436  0.88007443  0.68498907  0.61195471]\n",
      " [ 0.11607995  0.14595493  0.29035437  0.72715633  0.37417535  0.08657232\n",
      "   0.30779817  0.69835329  0.47875413  0.73249154]\n",
      " [ 0.5596556   0.27247869  0.9719198   0.55968319  0.105354    0.70738405\n",
      "   0.07287268  0.16258502  0.66032304  0.24309054]]\n",
      "[ 1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1.\n",
      " -1.  1.  1. -1.  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "X = XY[:, :-1]\n",
    "y = XY[:, -1]\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.2 (0.2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрограммируйте вычисление функции L, используйте только матричные операции (внутри не должно быть циклов).\n",
    "\n",
    "**Замечание**: Нигде в промежуточных вычислениях не стоит вычислять значение $\\exp(−y_ix^Tw)$, иначе может произойти переполнение. Вместо этого следует напрямую вычислять необходимые величины с помощью специализированных для этого функций: `np.logaddexp` для `ln(1 + exp(·))` и `sp.special.expit` для `1/(1 + exp(-(·)))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(w, X, y) = \\frac1{N}\\sum_{i = 0}^{N} log (1 + exp(-y_ix_i^Tw)) + \\frac{C}{2} ||w||^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "\n",
    "def logistic(w, X, y):\n",
    "    \"\"\"\n",
    "        logistic(w, X, y) вычисляет функцию качества лог регрессии L(w, X, y)\n",
    "        \n",
    "        w: np.array размера (M,)\n",
    "        X: np.array размера (N, M)\n",
    "        y: np.array размера (M,)\n",
    "        \n",
    "        funcw: np.float \n",
    "    \"\"\"\n",
    "    return np.sum(np.logaddexp(0, -1 * y * np.dot(X, w))) / len(X) + C * (LA.norm(w) ** 2) / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3.1 (0.3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите градиент функции $\\nabla_w L(w, X, y)$, запишите в терминах матричных операций.\n",
    "\n",
    "Эффективно запрограммируйте вычисление градиента (опять же, только матричные операции!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_{w_k} L(w, X, y) = \\frac1{N}\\sum_{i = 0}^{N} -\\frac{y_ix_{i,k}}{e^{y_ix_{i}^Tw}+1}+C ||w_k||$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "import numpy.linalg as LA\n",
    "\n",
    "def logistic_grad(w, X, y):\n",
    "    '''\n",
    "        logistic_grad(w, X, y) вычисляет градиент функции качества лог регрессии dL(w, X, y)/dw\n",
    "        \n",
    "        w: np.array размера (M,)\n",
    "        X: np.array размера (N, M)\n",
    "        y: np.array размера (M,)\n",
    "        \n",
    "        gradw: np.array размера (M,)\n",
    "    '''\n",
    "    def grad(k):\n",
    "        return np.sum((-1 * y * X.T[k]) * expit(-1 * y * np.dot(X, w))) / len(X) + C * LA.norm(w[k])\n",
    "    return np.fromfunction(np.vectorize(grad), w.shape, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(logistic_grad(w, X, y).shape == w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.3.2 (0.3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень часто при подсчёте градиента допускаются ошибки, проверьте правильность реализации подсчёта градиента с помощью конечных разностей. \n",
    "\n",
    "$$[\\nabla f(x)]_i \\approx \\frac{f(x + \\varepsilon \\cdot e_i) - f(x)}{\\varepsilon}~~~~$$\n",
    "\n",
    "где $e_i = (0, ... , 0, 1, 0, ..., 0)$ - i-й базисный орт, $\\epsilon \\approx 10^{-8}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_error(a, b): \n",
    "    return np.max(np.abs(a - b))\n",
    "\n",
    "\n",
    "def grad_finite_diff(func, x, eps=1e-8):\n",
    "    \"\"\"\n",
    "        w: np.array размера (M,)\n",
    "        func: скалярная функция от векторного аргумента w, func(w) =  число\n",
    "        eps: np.float константа для проверки градиента\n",
    "        \n",
    "        dnum: np.array размера (M,), численно посчитанный градиент\n",
    "    \"\"\"\n",
    "    x, fval, dnum = x.astype(np.float64), func(x), np.zeros_like(x)\n",
    "\n",
    "    def grad_diff(i):\n",
    "        e_i = np.zeros_like(w); e_i[i] = 1\n",
    "        return (func(x + eps * e_i) - fval) / eps\n",
    "    \n",
    "    return np.fromfunction(np.vectorize(grad_diff), w.shape, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err =  3.26100205728e-08 ok\n"
     ]
    }
   ],
   "source": [
    "mat_grad = logistic_grad(w, X, y)\n",
    "num_grad = grad_finite_diff(lambda w: logistic(w, X, y), w)\n",
    "\n",
    "err = max_error(mat_grad, num_grad)\n",
    "print('err = ', err, 'ok' if err < 1e-6 else 'ошибка очень большая!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.4.1 (0.4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач оптимизации очень удобно использовать гессиан.\n",
    "\n",
    "Вычислите гессиан для функции L, запишите ответ в терминах матричных операций. Эффективно запрограммируйте вычисление гессиана."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\nabla_{w_iw_j} L(w, X, y) = \\frac1{N}\\sum_{k = 0}^{N} \\frac{y_k^2x_{k,i}x_{k,j}e^{y_kx_{k}^Tw}}{(e^{y_kx_{k}^Tw}+1)^2}+C_{[i == j]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_hess(w, X, y):\n",
    "    \"\"\"\n",
    "        logistic_hess(w, X, y) вычисляет гессиан функции качества лог регрессии dL(w, X, y)/dw\n",
    "        \n",
    "        w: np.array размера (M,)\n",
    "        X: np.array размера (N, M)\n",
    "        y: np.array размера (M,)\n",
    "        \n",
    "        hessw: np.array размера (M, M)\n",
    "    \"\"\"\n",
    "    \n",
    "    def gaussian(i, j):\n",
    "        part_sums = ((y ** 2) * X.T[i] * X.T[j]) * expit(-1 * y * np.dot(X, w)) * expit(y * np.dot(X, w))\n",
    "        return np.sum(part_sums) / len(X) + C * (i == j)\n",
    "\n",
    "    return np.fromfunction(np.vectorize(gaussian), (w.shape[0], w.shape[0]), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(logistic_hess(w, X, y).shape == (w.shape[0], w.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2.4.2 (0.4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим правильность реализации подсчёта гессиана.\n",
    "\n",
    "Для гессиана проверка выглядит похожим образом\n",
    "\n",
    "$$[\\nabla^2 f(x)]_{ij} \\approx \\frac{f(x + \\varepsilon \\cdot e_i + \\varepsilon \\cdot e_j) -f(x + \\varepsilon \\cdot e_i) - f(x + \\varepsilon \\cdot e_j)+ f(x)}{\\varepsilon^2}~~~~~~~~~~~~~~~~~~~~~$$\n",
    "\n",
    "где $e_i = (0, ... , 0, 1, 0, ..., 0)$ - i-й базисный орт, $\\varepsilon \\approx 10^{-4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hess_finite_diff(func, w, eps=1e-4):\n",
    "    '''\n",
    "        w: np.array размера (M,)\n",
    "        func: скалярная функция от векторного аргумента w, func(w) =  число\n",
    "        eps: np.float константа для проверки градиента\n",
    "        \n",
    "        dnum: np.array размера (M,), численно посчитанный градиент\n",
    "    '''\n",
    "    w, fval, dnum = w.astype(np.float64), func(w).astype(np.float64), np.zeros((w.size, w.size), dtype=np.float64)\n",
    "\n",
    "    def hess_diff(i, j):\n",
    "        e_i = np.zeros_like(w); e_i[i] = 1\n",
    "        e_j = np.zeros_like(w); e_j[j] = 1\n",
    "        return (func(w + eps * (e_i + e_j)) - func(w + eps * e_i) - func(w + eps * e_j) + fval) / (eps ** 2)\n",
    "    \n",
    "    return np.fromfunction(np.vectorize(hess_diff), (w.shape[0], w.shape[0]), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err =  1.68779529248e-06\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "mat_grad = logistic_hess(w, X, y)\n",
    "num_grad = hess_finite_diff(lambda w: logistic(w, X, y), w)\n",
    "\n",
    "err = max_error(mat_grad, num_grad)\n",
    "\n",
    "print('err = ', err)\n",
    "print('ok' if max_error(mat_grad, num_grad) < 1e-4 else 'ошибка очень большая!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
